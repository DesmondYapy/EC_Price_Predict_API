Cloud Architecture

For deploying the ML model as a RESTful API, I propose using AWS EC2 as the primary compute resource. The architecture consists of the following components:

EC2 Instance:
Purpose: Hosts the Python API that serves the ML model.
Configuration: Select an appropriate instance type (e.g., t2.micro or t3.medium) based on expected traffic and computational needs. The instance will run the Docker container with the API and any necessary dependencies.
Security: Implement security groups to control inbound and outbound traffic, ensuring that only authorized users can access the API.

PostgreSQL Database:
Purpose: Stores the data retrieved from URAâ€™s private residential property transactions API, along with any additional data sources used for the ML model.
Option: This can be set up either on the same EC2 instance or as a managed service using Amazon RDS for PostgreSQL to enhance scalability and ease of management.

S3 Bucket (Optional):
Purpose: Stores datasets, model artifacts, or any logs generated by the API.
Use Case: This can be useful for versioning datasets or storing backups of the model.

CloudWatch (Optional):
Purpose: Monitors the performance and health of the EC2 instance and the API.
Features: Can be configured to set alarms based on metrics such as CPU usage, memory usage, and API request counts.

Load Balancer (Optional):
Purpose: Distributes incoming API requests across multiple EC2 instances to ensure high availability and fault tolerance.
Scalability: As demand grows, additional EC2 instances can be added behind the load balancer.
